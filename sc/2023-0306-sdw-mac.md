# 在MacAir上搭建人工智能AI画图环境

在MacAir上，可以通过开源的Stable Diffusion项目自行搭建AI画图环境，这里以Intel处理器的Mac Air为例。

Stable Diffusion项目硬件要求较高而且只提供终端命令行交互方式，所以这里使用stable-diffusion-webui项目（简称webui）来实现本地部署。webui项目为Stable Diffusion项目提供了web网页的交互方式，操作更简单。

## 环境部署

本机部署好git环境之后，正常情况直接执行webui的脚本即可运行，在终端里执行：

```
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
./webui.sh
```

执行过程中会下载一些文件，如果中途出现错误，重新执行webui.sh即可。

如果提示opencv版本太老，可以这样手工更新一下：

```
# ImportError: dlopen(/github/stable-diffusion-webui/venv/lib/python3.10/site-packages/cv2/cv2.abi3.so, 2): Symbol not found: _VTRegisterSupplementalVideoDecoderIfAvailable
cd venv/bin
source activate
./python3.10 -m pip install --upgrade pip
pip3 install opencv-python==4.6.0.66
deactivate
```

如果提示显卡问题，可以这样处理：

```
# RuntimeError: "LayerNormKernelImpl" not implemented for 'Half'
cd venv/bin
source activate
pip install torch --extra-index-url https://download.pytorch.org/whl/cu113
deactivate
```

编辑`webui-user.sh`，添加：

```
export COMMANDLINE_ARGS="--precision full --no-half --skip-torch-cuda-test
```

如果顺利地跑成功了，会看到类似这样的提示：

```
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
Applying cross attention optimization (InvokeAI).
Textual inversion embeddings loaded(0):
Model loaded in 31.0s (load weights from disk: 0.7s, create model: 1.1s, apply weights to model: 28.5s, apply dtype to VAE: 0.2s, load textual inversion embeddings: 0.3s).
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`
```

此时只要打开浏览器访问对应的地址`http://127.0.0.1:7860`即可使用了。

## 模型下载

webui默认不带模型文件，需要自己下载后放到对应的目录中，模型文件可以去以下两个网站中下载：

- https://huggingface.co/
- https://civitai.com/

根据模型的类型不同，放置在不同的目录下：

- 主模型文件，放置在：stable-diffusion-webui/models/Stable-diffusion
- Lora文件，放置在：stable-diffusion-webui/models/Lora
- VAE文件，放置在：stable-diffusion-webui/models/VAE

也有一类Lora文件和主模型同名的，需要放置在Stable-diffusion目录下。

模型下载之后，刷新浏览器页面，就可以看到模型文件了。切换模型文件需要重新加载，请耐心等待。

如果prompt不会写，可以参考模型页面上prompt的写法。

## 花絮

对于Stable Diffusion，我们采访了chatGPT：

```
你知道开源项目Stable Diffusion吗？

很抱歉，作为一个语言模型AI，我无法知道所有的开源项目。Stable Diffusion似乎不是一个很有名的开源项目，我无法提供更多的信息。如果您愿意提供更多背景信息，我会尽力回答。
```

chatGPT这是故意...


稳定扩散（Stable Diffusion）是一个潜在的文本到图像的扩散模型，能够在任何文本输入的情况下生成照片般逼真的图像，培养自主的自由度以产生令人难以置信的图像，使数十亿人在几秒钟内创造出令人惊叹的艺术。

简单来说，就是大家常说的AI画图工具，可以实现文字描述转图片，或者图片转图片等功能。

AI画图的第一轮火爆出圈，是 openAI 在2021年发布的 DALL-E 产品，它可以理解自然语言输入，并根据文字描述生成图片。第二年，在美国的一次美术比赛中，一位名叫杰森·艾伦（Jason Allen）的艺术家借助 AI 工具 Midjourney 创造的作品获得了第一名:

![Theatre Dopera Spatial](res/1.png)

同年，慕尼黑大学 CompVis 小组发布了 Stable Diffusion ，是一种深度学习、文本到图像模型，主要用于生成以文本描述为条件的详细图像。

目前，国内很多提供文字绘图的网站，应该都是利用 Stable Diffusion 这个开源项目实现的功能。

